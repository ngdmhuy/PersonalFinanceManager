% =============================================================
% BATCH 1: EXPANDED REQUIREMENTS & ARCHITECTURAL FOUNDATION
% =============================================================

\section{Requirements Specification for Core Logic Engine}
\label{sec:requirements_specification}

The \texttt{AppController} serves as the computational heart of the Personal Finance Manager. As the M2 engineer, I defined a set of rigorous requirements to ensure the system handles sensitive financial data with absolute precision and stability.

\subsection{Functional Requirements (FR) and Logic Boundaries}
The logic layer must orchestrate all data flow while adhering to the following functional mandates:
\begin{itemize}
    \item \textbf{FR-M2-1: Deterministic State Management:} The system must provide a robust CRUD (Create, Read, Update, Delete) interface for Wallets, Categories, and Transactions. Every state mutation must be deterministic, meaning identical inputs must yield identical binary outputs.
    \item \textbf{FR-M2-2: Financial Synchronization:} Any transaction entry (Income/Expense) must trigger an immediate, atomic update of the associated Wallet balance. The system must prevent "Phantom Balances" where a transaction exists but the wallet remains un-updated.
    \item \textbf{FR-M2-3: Temporal Reconciliation (Catch-up):} Upon startup, the logic engine must scan the \texttt{RecurringTransactions} registry and automatically generate missing entries for the period the application was inactive.
    \item \textbf{FR-M2-4: Referential Integrity Enforcement:} To prevent data corruption, the system shall simulate SQL-like "Restrict-Delete" constraints. A Category or Wallet cannot be purged if it is referenced by any historical transaction.
\end{itemize}

\subsection{Non-Functional Technical Constraints (NFR)}
To fulfill the requirements of a high-performance C++ application under limited library support, the following constraints were established:
\begin{itemize}
    \item \textbf{NFR-M2-1: Manual Resource Management (STL Independence):} The logic layer is strictly prohibited from using STL containers (e.g., \texttt{std::vector}, \texttt{std::map}). I engineered custom \texttt{ArrayList} and \texttt{HashMap} structures to manage the Heap memory lifecycle manually.
    \item \textbf{NFR-M2-2: Thread Concurrency and Race Condition Prevention:} The system must remain thread-safe during background I/O operations. I implemented a locking strategy using \texttt{std::recursive_mutex} to allow nested controller calls without causing deadlocks.
    \item \textbf{NFR-M2-3: Data Persistence Latency:} The serialization process (\texttt{SaveData}) must occur asynchronously or be optimized for sub-millisecond execution to avoid freezing the UI thread.
\end{itemize}

\section{System Architecture and Controller Design Philosophy}
\label{sec:system_architecture}

The architecture follows a centralized **Mediator Pattern**, where the \texttt{AppController} acts as the singular bridge between the User Interface and the Persistence Layer.



\subsection{The Multi-Layered Data Orchestration}
The internal structure of the controller is designed for high-speed indexing and memory safety:
\begin{enumerate}
    \item \textbf{Ownership Layer:} The \texttt{AppController} maintains exclusive ownership of all entity pointers. This "Single Owner" principle ensures that memory deallocation in the destructor is clean and predictable.
    \item \textbf{Indexing Layer:} I implemented dual-indexing using \texttt{ArrayLists} for chronological data display and \texttt{HashMaps} for $O(1)$ ID-to-Object mapping. This hybrid approach optimizes both report generation and individual record editing.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{img/app_header.png}
    \caption{The Structural Backbone: AppController’s Private Member Registries and Mutexes}
    \label{fig:appcontroller_header}
\end{figure}

\subsection{Lifecycle and Destruction Protocol}
In a system managing raw pointers, the lifecycle end-point is critical. My implementation of the destructor ensures that all resources—including joined background threads—are terminated gracefully.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{img/destructor.png}
    \caption{Memory Deallocation Workflow: Ensuring Zero-Leak Termination}
    \label{fig:destructor_impl}
\end{figure}

The \texttt{FreeList} helper function (seen in the image above) is a template-based utility I designed to iterate through our custom containers and safely \texttt{delete} each object on the Heap before the container itself is destroyed. This rigor is what allows the Personal Finance Manager to maintain a stable memory footprint over long sessions.
% =============================================================
% BATCH 2: CORE CRUD LOGIC & FINANCIAL STATE MANAGEMENT
% =============================================================

\section{Implementation of Core Business Logic (CRUD Operations)}
\label{sec:crud_logic_implementation}

The \texttt{AppController} functions as the primary engine for executing Create, Read, Update, and Delete (CRUD) operations. In a high-performance C++ environment without an RDBMS, these operations require manual orchestration of pointer logic and strict synchronization between memory and binary storage.

\subsection{Advanced Transaction Creation and Resource Allocation}
The creation of a financial record is an atomic workflow designed to prevent inconsistent states between the transaction log and wallet balances.

\begin{enumerate}
    \item \textbf{Unique Identity Attribution:} Upon a create request, the controller invokes the \texttt{IdGenerator} to assign a prefix-coded ID (e.g., \texttt{TRA-XXXX}). Uniqueness is verified via an $O(1)$ collision check against the internal \texttt{transactionsMap}.
    \item \textbf{Dynamic Financial Mutation:} The controller resolves the pointer to the target \texttt{Wallet} entity. Depending on the \texttt{TransactionType} (Income or Expense), the internal state is mutated:
    \begin{itemize}
        \item \textbf{Inflow:} \texttt{wallet->AddAmount(val)} increments the specific asset balance.
        \item \textbf{Outflow:} \texttt{wallet->SubtractAmount(val)} decrements the balance, with an optional check for negative thresholds.
    \end{itemize}
    \item \textbf{Chronological Indexing:} To optimize subsequent retrieval, transactions are not merely appended; they are inserted using a "Sorted Insertion" strategy via \texttt{GetSortedInsertIndex}. This ensures the \texttt{ArrayList} remains an ordered sequence by date, enabling logarithmic search performance.
\end{enumerate}

\subsection{Relational Data Retrieval and View Mapping}
Retrieving data requires a "Runtime Join" mechanism to transform normalized IDs into user-friendly information.

\begin{itemize}
    \item \textbf{ID-to-Object Resolution:} During report generation, the controller uses the stored \texttt{WalletID} and \texttt{CategoryID} to perform $O(1)$ lookups in the \texttt{HashMap} registries.
    \item \textbf{Memory-Efficient Result Sets:} Instead of deep-copying objects, retrieval functions return a new \texttt{ArrayList} of existing pointers. This shallow-copy approach minimizes memory bandwidth overhead while allowing the View layer to access the "Single Source of Truth".
\end{itemize}



\subsection{The Delta-Update Mechanism for Financial Accuracy}
Updating a record is the most technically nuanced CRUD operation. To avoid compounding errors, the \texttt{AppController} implements a "Revert-then-Apply" logic:
\begin{itemize}
    \item When an amount is modified, the controller first calculates the difference (Delta).
    \item The original transaction effect is reverted from the wallet balance to reset the state.
    \item The new amount is applied, and the object is re-indexed if the date was changed.
\end{itemize}

\subsection{Referential Integrity and Protective Deletion}
To simulate the "ON DELETE RESTRICT" constraint of professional databases, I engineered a usage-check algorithm in the deletion sequence.

\begin{lstlisting}[language=C++, caption={Data Integrity Protection in Deletion Logic}]
bool AppController::DeleteCategory(const std::string& id) {
    std::lock_guard<std::recursive_mutex> lock(dataMutex);
    
    // Integrity Check: Iterating through transaction history
    for (size_t i = 0; i < transactions->Count(); ++i) {
        if (transactions->Get(i)->GetCategoryId() == id) {
            return false; // Deletion blocked to prevent dangling pointers
        }
    }
    // Execution: Safe removal from Memory and Map
    return FinalizeDeletion(id);
}
\end{lstlisting}

As evidenced in the code above, the controller scans both historical \texttt{transactions} and future \texttt{recurringTransactions} templates. Only when the entity is proved to be "Safe to Delete" does the controller remove it from the registries and invoke the \texttt{delete} operator to reclaim Heap memory.

\subsection{Write-Through Persistence Strategy}
The logic engine employs a **Write-Through** persistence model to ensure zero data loss. Every successful CRUD mutation triggers an immediate serialization call to the \texttt{BinaryFileHelper}. This ensures that the binary state on disk is always a mirror image of the high-speed data structures in RAM.
% =============================================================
% BATCH 3: KEY ALGORITHMS & PERFORMANCE OPTIMIZATION
% =============================================================

\section{Key Algorithms and Computational Optimization}
\label{sec:key_algorithms}

The efficiency of the \texttt{AppController} is defined by its ability to process thousands of financial records with minimal latency. Since the project operates under a "No STL" constraint, I engineered custom algorithms for searching, filtering, and data aggregation, focusing on minimizing time complexity.

\subsection{Optimized Temporal Search via Hybrid Binary Search}
Standard linear scanning for date-range reports results in $O(N)$ complexity, which degrades performance as the transaction history grows. To optimize this, I implemented a \textbf{Hybrid Binary Search} algorithm.

\subsubsection{Algorithm Mechanism}
The algorithm exploits the fact that the master transaction list is maintained in a sorted state by date. 
\begin{enumerate}
    \item \textbf{Phase 1 (Logarithmic Indexing):} The system performs a Binary Search to locate the \textit{Lower Bound} (the index of the first transaction $\geq StartDate$).
    \item \textbf{Phase 2 (Linear Collection):} Starting from the discovered index, the controller performs a single-pass scan to collect all records until the \textit{EndDate} is exceeded.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{img/filtering.png}
    \caption{Binary Search Implementation for $O(\log N + K)$ Transaction Retrieval}
    \label{fig:binary_search_impl}
\end{figure}

\subsubsection{Complexity Analysis}
The time complexity of this retrieval is defined as:
\begin{equation}
    T(n) = O(\log N) + O(K)
\end{equation}
Where $N$ is the total number of transactions and $K$ is the number of results in the specified range. Compared to a naive $O(N)$ scan, this approach significantly reduces CPU cycles for annual or monthly reporting.

\subsection{Multi-Criteria Filtering and Pointer-Based Result Sets}
Generating specialized reports (e.g., "Expenses by Category in Wallet A") requires a flexible filtering engine. 



\begin{itemize}
    \item \textbf{Predicate Logic:} The controller utilizes a composite predicate evaluation system where each transaction is checked against multiple criteria (Category, Wallet, and Date) in a single pass.
    \item \textbf{Memory Efficiency via Shallow Copying:} To avoid redundant Heap allocations, the filtering engine creates a new \texttt{ArrayList} containing only the memory addresses (pointers) of the matching transactions. This ensures that the memory footprint remains constant regardless of the result set size.
\end{itemize}

\subsection{Thread-Safe Aggregation Algorithms}
Aggregation functions such as \texttt{CalculateTotalIncome()} must handle concurrent access to prevent "Dirty Reads".

\begin{lstlisting}[language=C++, caption={Thread-Safe Aggregation Logic}]
double AppController::CalculateTotal(Date start, Date end, TransactionType type) {
    std::lock_guard<std::recursive_mutex> lock(dataMutex); // Protecting state
    double total = 0.0;
    ArrayList<Transaction*>* filtered = GetTransactionsByDateRange(start, end);
    
    for(size_t i = 0; i < filtered->Count(); ++i) {
        if(filtered->Get(i)->GetType() == type) {
            total += filtered->Get(i)->GetAmount();
        }
    }
    delete filtered; // Cleanup temporary pointer list
    return total;
}
\end{lstlisting}

\subsubsection{Safety Protocol}
As seen in the implementation, the use of \texttt{std::lock_guard} ensures that the aggregation remains consistent even if a background auto-save or a concurrent update occurs. The \texttt{recursive_mutex} is essential here because \texttt{CalculateTotal} calls \texttt{GetTransactionsByDateRange}, which also attempts to acquire the lock.

\subsection{Data Normalization and "Join" Logic}
Since our storage model is normalized to save disk space, displaying information requires a runtime "Join" algorithm.
\begin{itemize}
    \item \textbf{The Mapping Problem:} Transactions store only \texttt{walletID} (string).
    \item \textbf{The Solution:} I implemented a $O(1)$ mapping logic where the controller uses the \texttt{ID} as a key to retrieve the full \texttt{Wallet*} object from the \texttt{walletsMap}. This allows the UI to display the "Wallet Name" instead of a cryptic ID without performing expensive string comparisons.
\end{itemize}
% =============================================================
% BATCH 4: AUTOMATED RECURRING TRANSACTION LOGIC
% =============================================================

\section{Automated Recurring Transaction Engine}
\label{sec:recurring_logic}

One of the most sophisticated features of the \texttt{AppController} is the \textbf{Automated Recurring Transaction Engine}. This module ensures that fixed financial obligations, such as monthly rent or weekly subscriptions, are recorded with absolute precision without requiring manual user input for every occurrence.

\subsection{The "Temporal Gap" Challenge}
A significant challenge for desktop-based financial applications is the "Downtime Problem." Unlike server-side applications, this system only executes when the user opens the application. If a user closes the app on Monday and reopens it on Friday, any daily recurring transactions for Tuesday, Wednesday, and Thursday must be accounted for. 

\subsection{The "Catch-up" Synchronization Algorithm}
To solve this, I engineered a "Catch-up" algorithm within the \texttt{ProcessRecurringTransactions} method. This algorithm is invoked during the application's boot sequence to reconcile the internal state with the current system time.



\subsubsection{Algorithmic Execution Flow}
The algorithm operates as a temporal state machine:
\begin{enumerate}
    \item \textbf{Snapshotting:} The system captures the current system date ($T_{now}$).
    \item \textbf{Predicate Evaluation:} For each template in the \texttt{recurringTransactions} list, the controller evaluates the condition: $NextDueDate \leq T_{now}$.
    \item \textbf{Iterative Generation:} I implemented a \texttt{while} loop to handle multiple missed cycles. This is a critical design choice—if the app was inactive for three months, a monthly recurring item will trigger three distinct transaction generations sequentially.
    \item \textbf{Resource Propagation:} Each generated transaction is assigned a unique ID, inserted into the sorted master list, and its effect is immediately applied to the corresponding wallet's balance.
    \item \textbf{State Update:} The \texttt{NextDueDate} of the template is incremented based on its frequency (Daily, Weekly, Monthly, or Yearly), and the \texttt{LastGeneratedDate} is updated.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{img/recurring.png}
    \caption{Implementation of the Temporal Catch-up Logic for Missed Recurring Entries}
    \label{fig:recurring_logic_impl}
\end{figure}

\subsection{Collision Prevention and ID Integrity}
During the automated generation process, the controller must ensure that newly created transaction IDs do not collide with existing ones in the binary database.

\begin{lstlisting}[language=C++, caption={Collision-Resistant ID Generation in Recurring Logic}]
do {
    newTransId = IdGenerator::GenerateId(prefix);
} while (transactionsMap->ContainsKey(newTransId)); // Ensuring uniqueness
\end{lstlisting}

This \texttt{do-while} construct, combined with the $O(1)$ lookup capability of our custom \texttt{HashMap}, ensures that the automation engine can safely generate hundreds of records without data corruption.

\subsection{Asynchronous Persistence of Automated Changes}
Because the Catch-up process can modify a large volume of data during startup, the \texttt{AppController} triggers a comprehensive \texttt{SaveData()} call after the loop completes. This ensures that all automatically generated transactions are committed to the binary files immediately, maintaining synchronization between the physical storage and the volatile memory.

\subsection{System Impact and Accuracy}
By offloading this logic to the \texttt{AppController}, the application achieves "Maintenance-Free" financial tracking. The accuracy of the wallet balances is preserved regardless of how frequently the user interacts with the system, fulfilling a key requirement for reliable personal finance management.
% =============================================================
% BATCH 5: TESTING STRATEGY & QUALITY ASSURANCE
% =============================================================

\section{Testing Strategy and Quality Assurance}
\label{sec:testing}

Verification and validation of the \texttt{AppController} logic were paramount to ensure financial data integrity. Given the manual memory management and custom data structures, I implemented a multi-tiered testing strategy focusing on logic correctness, boundary conditions, and memory stability.

\subsection{Unit Testing of Core Logic}
Each independent function within the controller was subjected to unit tests to verify its mathematical and logical accuracy.

\begin{itemize}
    \item \textbf{Financial Math Verification:} I tested the \texttt{AddAmount} and \texttt{SubtractAmount} flows to ensure that floating-point operations do not result in precision loss over thousands of iterations.
    \item \textbf{Sorted Indexing Test:} I verified that the \texttt{GetSortedInsertIndex} function correctly identifies the position for new transactions, even when multiple records share the same timestamp.
    \item \textbf{ID Collision Testing:} A stress test was conducted by generating 10,000 transactions in a loop to ensure the \texttt{IdGenerator} and \texttt{HashMap} collision-check logic remains robust.
\end{itemize}

\subsection{Integration Testing: Persistence and Concurrency}
Integration tests focused on the interaction between the \texttt{AppController}, the filesystem, and background threads.

\begin{enumerate}
    \item \textbf{Binary Serialization Integrity:} I performed "Round-trip" tests where a complex state (multiple wallets, categories, and hundreds of transactions) was saved to binary files and then reloaded. The memory state after loading was compared against the pre-save state to ensure bit-perfect restoration.
    \item \textbf{Concurrency Stress Test:} To test the \texttt{recursive_mutex} implementation, I simulated a scenario where a background auto-save occurs exactly during a massive data filter operation. The system maintained stability without deadlocks or race conditions.
\end{enumerate}

\subsection{Edge Case Scenarios and Robustness}
I identified and tested several critical edge cases that could lead to system failure:



\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Test Case} & \textbf{Scenario Description} & \textbf{Expected Outcome} \\ \hline
Empty Registry & Loading application with no binary files. & Graceful initialization of empty lists. \\ \hline
Leap Year Automation & Recurring daily item during Feb 29th. & Correct generation of missed entries. \\ \hline
Zero Balance Delete & Attempting to delete a wallet with history. & Blocked by Integrity Check. \\ \hline
Large Dataset & Processing 50,000+ transaction records. & $O(\log N)$ search remains responsive. \\ \hline
\end{tabular}
\caption{Key Edge Case Testing Scenarios}
\end{table}

\subsection{Manual Memory Leak Analysis}
Since the project avoids STL smart pointers, I conducted manual leak detection during the runtime. 
\begin{itemize}
    \item \textbf{Technique:} I monitored the application's heap memory usage during repeated cycles of adding and deleting transactions.
    \item \textbf{Verification:} The memory footprint returned to its baseline level after each \texttt{FreeList} and \texttt{delete} operation in the destructor, confirming that all objects allocated on the heap were correctly reclaimed.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{img/restrict_delete.png}
    \caption{Testing the "Restrict Delete" Logic: Attempting to delete a Category used in existing Transactions}
    \label{fig:test_integrity}
\end{figure}

\subsection{Conclusion of Testing Phase}
The rigorous testing of the \texttt{AppController} confirms that the backend is resilient against user errors and system interruptions. The combination of thread-safe locking and referential integrity checks ensures that the Personal Finance Manager provides a professional-grade level of data security and reliability.
% =============================================================
% BATCH 6: CONCLUSION, LIMITATIONS & FUTURE WORK
% =============================================================

\section{Conclusion and System Evaluation}
\label{sec:conclusion}

The development of the \texttt{AppController} as the core logic engine of the Personal Finance Manager has successfully met all predefined functional and technical requirements. By centralizing business logic and implementing custom high-performance data structures, the system provides a reliable and responsive foundation for personal financial tracking.

\subsection{Summary of Technical Achievements}
Through the implementation of this module, several critical engineering milestones were achieved:
\begin{itemize}
    \item \textbf{High-Performance Data Orchestration:} The use of hybrid \texttt{ArrayList} and \texttt{HashMap} registries ensures $O(1)$ lookups and $O(\log N + K)$ retrieval speeds, maintaining responsiveness even with large datasets.
    \item \textbf{Absolute Data Integrity:} The "Restrict-Delete" strategy and "Revert-then-Apply" update logic guarantee that the financial state remains consistent and free of orphaned records.
    \item \textbf{Resource Safety:} The manual memory management protocol, verified by rigorous destruction sequences, ensures that the application operates without memory leaks or pointer corruption.
    \item \textbf{Operational Automation:} The Catch-up engine successfully bridge temporal gaps, providing a seamless user experience for recurring financial commitments.
\end{itemize}

\subsection{Known Limitations}
Despite its robustness, the current architecture has areas that could be further refined:
\begin{itemize}
    \item \textbf{Linear Aggregation Scalability:} While filtering is optimized, total balance aggregation still relies on a linear $O(K)$ pass over result sets. For extreme datasets, this could be improved using pre-computed caching.
    \item \textbf{Binary File Atomicity:} Currently, the entire binary file is overwritten during a save operation. While safe for personal use, a block-based storage approach would be more efficient for larger file sizes.
\end{itemize}

\subsection{Future Work and Extensions}
To elevate the \texttt{AppController} to a commercial-grade backend, several enhancements are proposed:



\begin{enumerate}
    \item \textbf{Advanced Data Analytics Engine:} Implementing statistical algorithms (e.g., standard deviation of spending, trend forecasting) within the controller to provide deeper financial insights.
    \item \textbf{Data Encryption Layer:} Integrating an AES-256 encryption wrapper around the binary serialization process to protect sensitive financial information at rest.
    \item \textbf{Undo/Redo Command Pattern:} Implementing a stack-based Command Pattern within the controller to allow users to revert erroneous transactions or edits.
    \item \textbf{Cloud Synchronization Bridge:} Extending the \texttt{AppController} to support RESTful API calls for synchronizing the local binary state with a remote database.
\end{enumerate}

\subsection{Final Statement}
In conclusion, the \texttt{AppController} stands as a testament to the power of low-level C++ engineering. By bypassing the convenience of the STL and building a thread-safe, memory-efficient core from the ground up, I have ensured that the Personal Finance Manager is not just a functional tool, but a robust and scalable software system.
